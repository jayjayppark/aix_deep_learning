{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyORU6iRY6HoLvzfTAcGhotQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayjayppark/aix_deep_learning/blob/new-branch/final_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv2So16rWbTG"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "with open(\"adult_data.json\", \"r\") as readit:\n",
        "    x = json.load(readit)\n",
        "\n",
        "df1 = pd.DataFrame(x)\n",
        "\n",
        "with open(\"adult_test.json\", \"r\") as readit:\n",
        "    x = json.load(readit)\n",
        "\n",
        "df2 = pd.DataFrame(x)\n",
        "\n",
        "# 데이터 작성자가 임의로 train, test데이터로 나눠놨던것을 다시 합치자.\n",
        "df = pd.concat([df1, df2])\n",
        "df.info()\n",
        "# info()로 확인해보니 nan인 데이터가 한개도 없다. 수치형데이터 6개 범주형데이터 9개가 있는것을 확인"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 확인해보니 곳곳에 ?값이 확인되었다.\n",
        "df"
      ],
      "metadata": {
        "id": "ArtAAQLGkhvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수치형 데이터들의 요약통계량 확인\n",
        "df.describe()\n",
        "# 나이는 17세부터 90세까지 있는것을 확인할수 있다. 일주일에 일하는 시간은 1시간부터 99시간 까지있고 평균은 40시간 이다."
      ],
      "metadata": {
        "id": "7ZVhf69EVFrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nan값의 갯수를 확인해보니 역시 없다고 나오지만 아까전에 ?값을 확인했으므로 ?값이 nan값이나 마찬가지다.\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "nuQ9G6jBZiua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ?를 nan값으로 바꿔주자.\n",
        "import numpy as np\n",
        "\n",
        "df[df == '?'] = np.nan"
      ],
      "metadata": {
        "id": "AJWQg2s_lCC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "vt9bXmZDlV1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nan값이 있는 행은 전부 지워준다. 총 3,620개를 지워 45,222개의 데이터가 남았다.\n",
        "df = df.dropna(axis = 0)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "dVEmqe_VqGbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class값이 이상하게 '<=50K', '>50K', '<=50K.', '>50K.' 뒤에 점이 붙은상태로 한개씩 또 있다. 바꿔주자\n",
        "df['class'].unique()"
      ],
      "metadata": {
        "id": "1N7sBPcD4UPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace({'class' : '<=50K.'}, '<=50K')\n",
        "df = df.replace({'class' : '>50K.'}, '>50K')"
      ],
      "metadata": {
        "id": "lNWI10XP4ddG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5만달러 이상버는 사람은 1로, 이하로 버는사람은 0으로 바꿔준다.\n",
        "df = df.replace({'class' : '<=50K'}, 0)\n",
        "df = df.replace({'class' : '>50K'}, 1)"
      ],
      "metadata": {
        "id": "jb7okDAg7Kkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['class'].unique()"
      ],
      "metadata": {
        "id": "8TJy8ukhql1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5만달러 이상버는 사람의 비율을 확인해보니 24.78퍼센트를 차지하고 있었다.\n",
        "a = df['class'].value_counts()\n",
        "print(a)\n",
        "income_rate = round(df['class'].value_counts()[1]/len(df) * 100, 2)\n",
        "print('income_rate', income_rate, '% of the dataset')"
      ],
      "metadata": {
        "id": "wSXvQekH4-mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize = (8,5))\n",
        "plt.title('Income Distribution of Adults', fontsize=18, fontweight='bold')\n",
        "percentage = df['class'].value_counts(normalize = True).rename_axis('income').reset_index(name = 'Percentage')\n",
        "\n",
        "ax = sns.barplot(x = 'income', y = 'Percentage', data = percentage.head(10), palette='Greens_r')\n",
        "for p in ax.patches:\n",
        "    width = p.get_width()\n",
        "    height = p.get_height()\n",
        "    x, y = p.get_xy()\n",
        "    ax.annotate(f'{height:.0%}', (x + width/2, y + height*1.02), ha='center', fontweight='bold')"
      ],
      "metadata": {
        "id": "rCosUrN0IGBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 이 연구의 목적은 사람들의 연수입 데이터를 보면서 어떤 요인이 고소득과 관련이 있는지를 확인해보고, 돈을많이 벌기위한 힌트를 얻는것이므로,\n",
        "바꿀수 없는 요인 ex)인종, 나라 ,성별 등은 제거해주겠다. 또한 education과 education-num이 겹치므로 education은 삭제해준다.\n",
        "'''"
      ],
      "metadata": {
        "id": "T_G98VdgwGyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['education', 'race', 'sex', 'native-country', 'fnlwgt'], axis=1)"
      ],
      "metadata": {
        "id": "yk-nbTe_wo1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결혼상태 컬럼을 보면 너무 상태가 많고, 나중에 라벨인코더로 숫자로 바꿔줄거니 간단하게 결혼함(1)과 싱글(0) 두개의 범주로 나눠준다\n",
        "df[\"marital-status\"].unique()"
      ],
      "metadata": {
        "id": "LOzBoMRezRg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"marital-status\"] = df[\"marital-status\"].replace(['Never-married','Divorced','Separated','Widowed'], 0)\n",
        "df[\"marital-status\"] = df[\"marital-status\"].replace(['Married-civ-spouse','Married-spouse-absent','Married-AF-spouse'], 1)"
      ],
      "metadata": {
        "id": "b5TyKyEhzR_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"marital-status\"].unique()"
      ],
      "metadata": {
        "id": "4Uolv9Jx2loA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = df.corr().round(2)\n",
        "sns.heatmap(data=correlation_matrix, annot=True)\n",
        "\n",
        "plt.show()\n",
        "# heatmap을 통해 수치형 데이터들과 class의 상관관계를 확인해보았다.\n",
        "# 대부분 양의 상관관계를 가짐을 알수있다.\n",
        "# 수입과 상관관계가 가장 큰 순서는 결혼여부(혼자사는지 여부)와 교육 수준, 나이, 주에 일하는 시간, 자본 소득, 자본 손해 순서였다."
      ],
      "metadata": {
        "id": "r3WJQah48pms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 다음으로 두번째로 상관계수가 큰 교육수준과 연수입의 관계를 그래프로 그려서 분석해보자.\n",
        "1번부터 16번까지 순서는 아래와 같다.\n",
        " ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th', 'HS-grad ',\n",
        " 'Some-college', 'Bachelors', 'Masters', 'Doctorate', 'Prof-school', 'Assoc-acdm', 'Assoc-voc']\n",
        " '''\n",
        "# 교육 수준이 높아질수록 5만달러 이상버는 사람의 비율이 높아지는것을 확인할수 있다.\n",
        "# 특히 석사에서 박사로 넘어갈때 5만달러 이상버는 사람의 퍼센트가 크게 뛰고 그 다음부터도 큰 폭으로 비율이 증가하는것을 확인할수있다.\n",
        "percent = sns.catplot(x=\"education-num\",y=\"class\",data = df, kind = \"bar\", palette = \"muted\")\n",
        "percent.despine(left=True)\n",
        "percent = percent.set_ylabels(\">50K probability\")"
      ],
      "metadata": {
        "id": "QX8xBoB7M-Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "qCnv-0mTKhjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수업시간에 배운 KNN모델과 random forest모델들을 써보고 두 모델의 예측성능을 비교해보겠다.\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "\n",
        "X = df.drop(\"class\",axis=1)\n",
        "y = df['class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y, random_state=42)\n",
        "#train test set의 class비율을 stratify = y를 함으로서 일정하게 맞춰준다.\n",
        "\n",
        "# knn으로 분류하기 위해 범주형 변수들을 LabelEncoder로 인코딩한다.\n",
        "categorical = ['workclass', 'occupation', 'relationship']\n",
        "\n",
        "for feature in categorical:\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        X_train[feature] = le.fit_transform(X_train[feature])\n",
        "        X_test[feature] = le.transform(X_test[feature])\n",
        "\n",
        "# StandardScaler로 데이터를 표준화한다.\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n",
        "\n",
        "X_test = pd.DataFrame(scaler.transform(X_test), columns = X.columns)\n",
        "\n",
        "# 2가지 머신러닝 모델을 불러온다.\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
        "rf_clf = RandomForestClassifier(random_state = 13, n_jobs=-1, n_estimators=100)"
      ],
      "metadata": {
        "id": "BEAcRRmKvQjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# 실제값과 예측값을 넣으면 accuracy, precision, recall, f1 score, roc_auc score를 구해주는 함수\n",
        "def get_clf_eval(y_test, pred):\n",
        "    acc = accuracy_score(y_test , pred)\n",
        "    pre = precision_score(y_test , pred)\n",
        "    re = recall_score(y_test , pred)\n",
        "    f1 = f1_score(y_test, pred)\n",
        "    auc = roc_auc_score(y_test, pred)\n",
        "\n",
        "    return acc, pre, re, f1, auc"
      ],
      "metadata": {
        "id": "lm-GTXH0DUMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델과 train_test split한 데이터들을 넣어주면 성능평가 지표들을 구해주는 함수\n",
        "def get_result(model, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "\n",
        "    return get_clf_eval(y_test, pred)"
      ],
      "metadata": {
        "id": "0vD9WsmlDa86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 모델의 평가지표를 확인해보니 random forest 모델이 정확도도 더 높고 f1 score도 높아 정밀도와 재현율또한 더 높게 측정되었다.\n",
        "models = [knn_clf, rf_clf]\n",
        "model_names = ['KNeighbors', 'RandomForest']\n",
        "\n",
        "# 모델과 모델이름, train_test_split 데이터를 넣으면 성능평가지표를 모델별로 표로 보여주는 함수\n",
        "def get_result_pd(models, model_names, X_train, y_train, X_test, y_test):\n",
        "    col_names = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "    tmp = []\n",
        "\n",
        "    for model in models:\n",
        "        tmp.append(get_result(model, X_train, y_train, X_test, y_test))\n",
        "    return pd.DataFrame(tmp, columns=col_names, index=model_names)\n",
        "\n",
        "results = get_result_pd(models, model_names, X_train, y_train, X_test, y_test)\n",
        "results"
      ],
      "metadata": {
        "id": "grVca7u9Dct1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# 모델과 모델이름, test데이터를 넣으면 roc_curve를 그려주는 함수\n",
        "def draw_roc_curve(models, model_names, X_test, y_test):\n",
        "    plt.figure(figsize=(10,10))\n",
        "\n",
        "    for model in range(len(models)):\n",
        "        pred = models[model].predict_proba(X_test)[:, 1]\n",
        "        fpr, tpr, thresholds = roc_curve(y_test, pred)\n",
        "        plt.plot(fpr, tpr, label=model_names[model])\n",
        "\n",
        "    plt.plot([0,1], [0,1], 'k--', label='random quess')\n",
        "    plt.title('ROC')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "draw_roc_curve(models, model_names, X_test, y_test)"
      ],
      "metadata": {
        "id": "C-n5YGhCD8u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random forest에 대해서 precision-recall curve 출력해보기\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "pred_proba_c1 = rf_clf.predict_proba(X_test)[:, 1]\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n",
        "\n",
        "plt.figure(figsize = (8, 6))\n",
        "plt.plot(thresholds, precisions[:len(thresholds)],\n",
        "         linestyle = '--', label = 'precision')\n",
        "plt.plot(thresholds, recalls[:len(thresholds)], label = 'recall')\n",
        "plt.xlabel('Threshold value')\n",
        "plt.legend(); plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dWBFF0oyO3I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gridsearchcv를 통해 random forest모델의 성능개선해보기\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'max_depth' : [ 6, 8 ,10],\n",
        "    'n_estimators' : [50, 100, 200],\n",
        "    'min_samples_split' : [8, 12]\n",
        "}\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state=13, n_jobs=-1)\n",
        "grid_cv = GridSearchCV(rf_clf, param_grid=params, cv=2, n_jobs=-1)\n",
        "grid_cv.fit(X_train, y_train.values.reshape(-1,))"
      ],
      "metadata": {
        "id": "OJPqy6VaPPyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results_df = pd.DataFrame(grid_cv.cv_results_)\n",
        "cv_results_df.columns"
      ],
      "metadata": {
        "id": "OHURFpMsPbdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = ['rank_test_score', 'mean_test_score', 'param_n_estimators', 'param_max_depth', 'param_min_samples_split']\n",
        "cv_results_df[target_col].sort_values('rank_test_score').head()"
      ],
      "metadata": {
        "id": "r6RDyGrYPXrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_cv.best_params_"
      ],
      "metadata": {
        "id": "Wwac-vb3P6FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_cv.best_score_"
      ],
      "metadata": {
        "id": "dFdMFuNEP8-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grid search로 하이퍼파라미터 값을 변경해보며 최적의 파라미터를 적용해봤지만 accuracy는 별차이가 없었다.\n",
        "rf_clf_best = grid_cv.best_estimator_\n",
        "rf_clf_best.fit(X_train, y_train.values.reshape(-1,))\n",
        "\n",
        "pred1 = rf_clf_best.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test , pred1)"
      ],
      "metadata": {
        "id": "wreYcu-5P_n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 나머지 지표도 확인해보니 precision만 올라가고 다 조금씩 안좋아진것을 확인 할 수있었다.\n",
        "# 하지만 내가 생각하기에 5만달러가 안넘는 사람을 넘는다고 분류하는것이 더 안좋으므로 presion이 더 중요하다고 할수 있다.\n",
        "# 따라서 gridsearch로 찾은 best 모델을 이용하겠다.\n",
        "models = [knn_clf, rf_clf_best]\n",
        "model_names = ['KNeighbors', 'RandomForest']\n",
        "\n",
        "def get_result_pd(models, model_names, X_train, y_train, X_test, y_test):\n",
        "    col_names = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "    tmp = []\n",
        "\n",
        "    for model in models:\n",
        "        tmp.append(get_result(model, X_train, y_train, X_test, y_test))\n",
        "    return pd.DataFrame(tmp, columns=col_names, index=model_names)\n",
        "\n",
        "results = get_result_pd(models, model_names, X_train, y_train, X_test, y_test)\n",
        "results"
      ],
      "metadata": {
        "id": "ZJRthJr-Ripn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['hours-per-week'].unique()"
      ],
      "metadata": {
        "id": "PfkLxMOz3sUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 마지막으로 미래의 나의 데이터를 최종 모델에 집어넣어 연수입이 5만달러 이상일지 예측해보자!!\n",
        "\n",
        "me = pd.DataFrame([[35, 'Self-emp-inc', 11, 1, 'Tech-support', 'Husband', 200000, 0, 60]], columns = X_train.columns)\n",
        "\n",
        "\n",
        "for feature in categorical:\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        le.fit(df[feature])\n",
        "        me[feature] = le.transform(me[feature])\n",
        "\n",
        "me = pd.DataFrame(scaler.transform(me), columns = X.columns)\n",
        "pred_me = rf_clf_best.predict(me)\n",
        "print(pred_me)\n",
        "# 결과값은 1으로 연수입이 5만달러 이상이라고 예측하였습니다! 정확한 예측모델이군!!"
      ],
      "metadata": {
        "id": "ei6M94bqTBie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "vKqKMXHeZJN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "me"
      ],
      "metadata": {
        "id": "dy_kmeIMAkSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "_VEjS85LDz00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns[:]"
      ],
      "metadata": {
        "id": "7MXgF7MnWtFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical"
      ],
      "metadata": {
        "id": "jbtuQh6XT6IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "eJWiNcB_UJcv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}